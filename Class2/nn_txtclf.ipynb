{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "# Package imports\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sklearn\nimport sklearn.datasets\nimport sklearn.linear_model\nimport matplotlib\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom pprint import pprint\n\ncategories \u003d [\u0027alt.atheism\u0027, \u0027talk.religion.misc\u0027, \u0027comp.graphics\u0027, \u0027sci.space\u0027]\n\nnewsgroups_train \u003d fetch_20newsgroups(subset\u003d\u0027train\u0027,  categories\u003dcategories)\nnewsgroups_test \u003d fetch_20newsgroups(subset\u003d\u0027test\u0027,  categories\u003dcategories)"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "source": "num_train \u003d len(newsgroups_train.data)\nnum_test  \u003d len(newsgroups_test.data)\n\n# 提取tfidf特征 TODO\nvectorizer \u003d TfidfVectorizer(max_features\u003d20)\n\n# 对训练和测试数据一起提取特征\nX \u003d vectorizer.fit_transform( newsgroups_train.data + newsgroups_test.data )\n\n# 分离出训练数据和测试数据\nX_train \u003d X[0:num_train, :]\nX_test \u003d X[num_train:num_train+num_test,:]\n\nY_train \u003d newsgroups_train.target\nY_test \u003d newsgroups_test.target\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "(2034, 20) (2034,)\n(1353, 20) (1353,)\n  (0, 6)\t0.15061975673760045\n  (0, 16)\t0.6389485216306471\n  (0, 15)\t0.19418765044565436\n  (0, 19)\t0.3371340528582322\n  (0, 18)\t0.3314213652868753\n  (0, 10)\t0.09947619820914738\n  (0, 1)\t0.23949029269098682\n  (0, 0)\t0.08820051463501803\n  (0, 17)\t0.11347691666509696\n  (0, 9)\t0.27805128182293154\n  (0, 11)\t0.11644981347701422\n  (0, 8)\t0.2562889435929243\n  (0, 3)\t0.11133077635077257\n  (0, 7)\t0.11599060547880218\n  (0, 5)\t0.09956817039037541\n  (0, 12)\t0.16620290450874828\n  (1, 6)\t0.07095837334797045\n  (1, 16)\t0.5267755723256666\n  (1, 15)\t0.3659344590203577\n  (1, 19)\t0.10588466616945869\n  (1, 18)\t0.5464749458513298\n  (1, 10)\t0.09372833105896626\n  (1, 1)\t0.11282611239100115\n  (1, 0)\t0.24931251447410008\n  (1, 9)\t0.08732836954382514\n  :\t:\n  (2032, 0)\t0.3291686056275266\n  (2032, 17)\t0.09411141466598104\n  (2032, 9)\t0.461200396540103\n  (2032, 11)\t0.09657696918444968\n  (2032, 8)\t0.1771264423463037\n  (2032, 7)\t0.04809806386346458\n  (2032, 5)\t0.20644069398705822\n  (2032, 12)\t0.1722992539429417\n  (2032, 4)\t0.0857866395749379\n  (2032, 13)\t0.04646460635287429\n  (2032, 2)\t0.10746973098849215\n  (2033, 6)\t0.052153605889331475\n  (2033, 16)\t0.16593176470907625\n  (2033, 15)\t0.13447885469051074\n  (2033, 19)\t0.07782403807433567\n  (2033, 18)\t0.11475798157467684\n  (2033, 10)\t0.6200034171116656\n  (2033, 0)\t0.24432252337386037\n  (2033, 9)\t0.4492975821286601\n  (2033, 11)\t0.16128767724799384\n  (2033, 8)\t0.1774852495775107\n  (2033, 5)\t0.0689529611538021\n  (2033, 12)\t0.11509885511915141\n  (2033, 4)\t0.2865347287825307\n  (2033, 2)\t0.35895811251843673\n2034\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "print(X_train.shape, Y_train.shape)\nprint(X_test.shape, Y_test.shape)\nprint(X_train)\nprint(len(X_train.toarray()))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "source": "# Helper function to plot a decision boundary.\n# If you don\u0027t fully understand this function don\u0027t worry, it just generates the contour plot below.\ndef plot_decision_boundary(pred_func):\n    # Set min and max values and give it some padding\n    x_min, x_max \u003d X[:, 0].min() - .5, X[:, 0].max() + .5\n    y_min, y_max \u003d X[:, 1].min() - .5, X[:, 1].max() + .5\n    h \u003d 0.01\n    # Generate a grid of points with distance h between them\n    xx, yy \u003d np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    # Predict the function value for the whole gid\n    Z \u003d pred_func(np.c_[xx.ravel(), yy.ravel()])\n    Z \u003d Z.reshape(xx.shape)\n    # Plot the contour and training examples\n    plt.contourf(xx, yy, Z, cmap\u003dplt.cm.Spectral)\n    plt.scatter(X[:, 0], X[:, 1], c\u003dy, cmap\u003dplt.cm.Spectral)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "source": "num_examples, input_dim \u003d X_train.shape # 样本数量，输入层维度（target种类数）\nepsilon \u003d 0.001 # 梯度下降学习率\nreg_lambda \u003d 0.01 # 正则化强度\nepochs \u003d 5000 # 梯度下降的次数:1个epoch表示过了1遍训练集中的所有样本",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [],
      "source": "def calculate_loss(model, X, y):\n    W1, b1, W2, b2 \u003d model[\u0027W1\u0027], model[\u0027b1\u0027], model[\u0027W2\u0027], model[\u0027b2\u0027]\n    #正向传播，计算预测值\n    z1 \u003d X.dot(W1) + b1\n    a1 \u003d np.tanh(z1)\n    z2 \u003d a1.dot(W2) + b2\n    exp_scores \u003d np.exp(z2)\n    probs \u003d exp_scores / np.sum(exp_scores, axis\u003d1, keepdims\u003dTrue)\n    # 计算损失\n    corect_logprobs \u003d -np.log(probs[range(num_examples), y])\n    data_loss \u003d np.sum(corect_logprobs)\n    #在损失上加上正则项（可选）\n    data_loss +\u003d reg_lambda/2 * (np.sum(np.square(W1)) + np.sum(np.square(W2)))\n    return 1./num_examples * data_loss",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [],
      "source": "# Helper function to predict an output (0 or 1)\ndef predict(model, x):\n    W1, b1, W2, b2 \u003d model[\u0027W1\u0027], model[\u0027b1\u0027], model[\u0027W2\u0027], model[\u0027b2\u0027]\n    # 正向传播\n    z1 \u003d x.dot(W1) + b1\n    a1 \u003d np.tanh(z1)\n    z2 \u003d a1.dot(W2) + b2\n    exp_scores \u003d np.exp(z2)\n    probs \u003d exp_scores / np.sum(exp_scores, axis\u003d1, keepdims\u003dTrue)\n    return np.argmax(probs, axis\u003d1)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "outputs": [],
      "source": "# 这个函数为神经网络学习参数并且返回模型\n# - nn_hdim: 隐藏层的节点数\n# - num_passes: 通过训练集进行梯度下降的次数\n# - print_loss: 如果是True, 那么每1000次迭代就打印一次损失值\ndef build_model(X, y, nn_hdims, epsilon, reg_lambda, num_passes\u003d20000,  print_loss\u003dFalse):\n    \n    # TODO: 先只用一种nn_hdim\n    nn_hdim \u003d nn_hdims[1]\n    \n    # 用随机数初始化参数\n    np.random.seed(0)\n    nn_input_dim \u003d int(X.shape[1])\n    nn_output_dim \u003d int(y.shape[0])\n    W1 \u003d np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim) # X(2034, 20) W1(20, nn_hdim)\n    b1 \u003d np.zeros((1, nn_hdim))\n    W2 \u003d np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim)\n    b2 \u003d np.zeros((1, nn_output_dim))\n\n    model \u003d {}\n \n    # 梯度下降\n    for i in range(0, num_passes):\n        # 正向传播，计算判断出的结果\n        z1 \u003d X.dot(W1) + b1\n        a1 \u003d np.tanh(z1)\n        z2 \u003d a1.dot(W2) + b2\n        exp_scores \u003d np.exp(z2)\n        probs \u003d exp_scores / np.sum(exp_scores, axis\u003d1, keepdims\u003dTrue)\n        \n        # 反向传播，对参数进行优化\n        delta3 \u003d probs\n        # TODO num_examples ?\u003d nn_input_dim\n        delta3[range(num_examples), y] -\u003d 1\n        dW2 \u003d (a1.T).dot(delta3)\n        db2 \u003d np.sum(delta3, axis\u003d0, keepdims\u003dTrue)\n        delta2 \u003d delta3.dot(W2.T) * (1 - np.power(a1, 2))\n        dW1 \u003d (X.T).dot(delta2)\n        db1 \u003d np.sum(delta2)\n        \n        # 添加正则项\n        dW2 +\u003d reg_lambda * W2\n        dW1 +\u003d reg_lambda * W1\n        \n        # 梯度下降更新参数\n        W1 +\u003d -epsilon * dW1\n        b1 +\u003d -epsilon * db1\n        W2 +\u003d -epsilon * dW2\n        b2 +\u003d -epsilon * db2\n        \n        # 为模型分配新参数\n        model \u003d {\u0027W1\u0027: W1, \u0027b1\u0027: b1, \u0027W2\u0027: W2, \u0027b2\u0027: b2}\n        \n        # 选择性打印loss\n        if print_loss and i % 1000 \u003d\u003d 0:\n            print(\"Loss after iteration\", i, calculate_loss(model, X, y))\n    return model",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "(2034, 20)\n\u003cclass \u0027scipy.sparse.csr.csr_matrix\u0027\u003e\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "nn_input_dim \u003d int(X_train.shape[0])\nnn_output_dim \u003d int(Y_train.shape[0])\nprint(X_train.shape)\nprint(type(X_train))\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Loss after iteration 0 6.645996899251569\n",
            "Loss after iteration 1000 14.62705215205021\n",
            "Loss after iteration 2000 14.201031228102151\n",
            "Loss after iteration 3000 14.887274985940781\n",
            "Loss after iteration 4000 12.183991265682822\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "model \u003d build_model(X_train, Y_train, [input_dim,16,8,4], epsilon, reg_lambda, epochs, print_loss\u003dTrue)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-2-27c305468bdb\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_correct\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----\u003e 2\u001b[1;33m \u001b[0mn_test\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0myp\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name \u0027X_test\u0027 is not defined"
          ],
          "ename": "NameError",
          "evalue": "name \u0027X_test\u0027 is not defined",
          "output_type": "error"
        }
      ],
      "source": "n_correct \u003d 0\nn_test \u003d X_test.shape[0]\nfor n in range(n_test):\n    x \u003d X_test[n,:]\n    yp \u003d predict(model, x)\n    print(yp)\n    # if yp \u003d\u003d Y_test[n] :\n    #     n_correct +\u003d 1.0\nprint(\u0027Accuracy %f \u003d %d / %d\u0027%(n_correct/n_test, int(n_correct), n_test) )",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}